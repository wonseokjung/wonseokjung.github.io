---
title: "Policy gradient - Actor Critic"
date: 2018-06-08 12:26:28 -0400
categories: Reinforcementlearning update
use_math : true
---






# Policy Gradient Methods - Actor Citic

Wonseok Jung

---

# 1. Actor-Critic Methods 

- Reinforce with baseline 방법은 policy와 state-value를 모두 학습한다. 
- 하지만 여기서 state-value가 critic이 아닌 baseline 이기에 actor-critic이라고 부르지 않는다. 



---

# 1.1 Applying Bootstrap

- REINFORCE 방법에서는 BootStrap을 하지 않고 Terminal state까지 받은 총 reward $G_t$ 를 Baseline과의 차이를 계산한다. 

- Bootstrapping으로 인해 생기는 bias는 variance를 낮추고 learning 속도를 빠르게 한다.
- 반면 REINFORCE는 unbias하지만, variance가 높으며 learning 속도가 느리다. 
- 또한 REINFORCE 는 online으로 학습할수 없기에 continuous problem에 적합하지 않다. 

---
# 1.2 REINFORCE algorithm with bootstrapping 

- Bootstrapping의 장점을 이용하여 REINFORCE algorithm에 적용한 알고리즘을 <span style="color:red">Actor-Critic Methods</span> 라고 한다. 

- Actor-Critic Methods의 update Rule은 다음과 같다.
	![bandicam 2018-06-08 10-19-54-830](https://user-images.githubusercontent.com/11300712/41134081-9123ab90-6b05-11e8-97ba-cf98ca8c988d.jpg)

---
## One-step Actor-critic (Episodic)

![bandicam 2018-06-08 13-36-49-121](https://user-images.githubusercontent.com/11300712/41139209-361712e8-6b21-11e8-8a9f-f6bfcf8b5375.jpg)

---
## Actor-Critic with Eligibility Traces(episodic)
![bandicam 2018-06-08 13-36-58-286](https://user-images.githubusercontent.com/11300712/41139210-364cb81c-6b21-11e8-969e-8aa70b7972f6.jpg)

---
# Summary
- Q-leraning, SARSA, MC와 같은 알고리즘은 action value를 측정하고, 이를 사용하여 actoin 을 선택한다. 
- 여기서는 action value를 estimate하지 않아도 parameterized policy를 배워 action을 선택하는 방법을 알아보았다. 
- 이를 Policy gradient 방법이라고 한다. 
- Policy gradient는 각 action을 선택할 확률을 구할 수 있으며 더이상 $\epsilon-greedy$와 같은 exploration 방법은 사용하지 않는다. 
---

- REINFORCE methods 는 state-value function을 baseline으로 추가하여 variance를 줄인다. 
- Bootstrapping을 사용한 TD방법은 Monte Carlo보다 variance를 줄이는 효과가 있다. 
- 이 방법은 REINFORCE 알고리즘에 적용하여 policy에 의해 선택된 action을 critic하는 algorithm을 Actor-Critic 이라고 한다. 



---
### References 

Policy Gradient 개념 및 REINFORCE 알고리즘, REINFORCE 알고리즘 with baseline 설명

https://github.com/wonseokjung/ReinforcementLearning_byWonseok/blob/master/8.%20Policy%20Gradient%20Methods/1.PG_REINFORCE/pgtoReinbase.pdf



