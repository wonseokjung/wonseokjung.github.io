---
title: "제1편: 강화학습의 거의 모든것"
date: 2018-4-13 12:26:28 -0400
categories: Reinforcementlearning update
use_math : true
---

# Reinforcement learning


### 제1편: 강화학습의 거의 모든것

순서

1.Introduction

2.강화학습

3.강화학습의 예

4.강화학습의 요소


## Introduction


- - -


아기가 자라면서, 주위를 바라보고, 팔을 들고, 노는 행동을 누군가가 가르쳐서 하는 것은 아닐것이다. 

하지만 아기는 느끼고, 행동하고, 들으며 환경과 연결되어있다. 

이 연결은 유아가 행동을 하므로서 변하는 환경과 같은 원인과 결과를 만드는 정보를 생성하며,

위와같은 상호작용으로부터 배우는 것이 learning and intelligence 이론의 근간이 된다. 


사람이나 동물이 어떻게 배우는지에 대해 이론적으로 접근하지 않고, 

인공지능 연구의 관점으로 수학적인 분석과, computation 실험으로 학습문제를 푸는것을 "Reinforcementlearning(강화학습)"이라고 한다. 




### 1.  강화학습(Reinforcement learning)


Reinforcement learning은 Reward(보상)을 최대화하기 위하여 action(행동)을 하기위해 배우는 것이다. 

Learner(배우는자)는 action을 해보며, reward를 가장 높게 받는 action을 찾는다. 

여기서 선택된 action이 당장의 action으로 인해 받는 reward 뿐만 아닌, 

다음의 상황 또는 다음 일어나게 될 reward에도 영향을 끼칠수도 있다.

Reinforcement learning의 아이디어는 dynamic system theory에서 가져왔으며,

dynamic system theory은 agent가 environment가 환경과 상호작용을 계속해서 하며 현실의 문제를 푼다는 것이다. 


Reinforcement learning은 supervised learning, unsupervised learning과 구분되어야 하는데, 

이유는 다음과 같다.

1.Supervised learning와는 달리 Labeled된 정답의 집합으로 부터 배우지 않는다.

2.Unsupervised learning처럼 labeled되지 않는 데이터의 모음에서 구조를 찾는 방법이 아니다.

그러므로 Reinforcement learning은 세번째 머신러닝의 패러다임으로 분류할수 있을 것이다. 


Reinforcement learning의 challenge중 하나는 

여러가지 action을 해보는 exploration과 reward를 더 많이 받는 action을 선택하는 exploitation에서

트레이드오프가 발생한다는 것이다. 


Agent는 reward를 더 많이 받는 action을 선택하기 위해 exploitation을 해야 하지만, 

여러가지 action을 골고루 해보며 많은 상황을 경험하기 위해서는 exploration을 해야하기 때문이다. 


Reinforcement learning은 "목표지향적"으로 학습을 하며, 목표를 이루기 위해 reward를 최대로 받는 action을 선택하기 위해 학습한다. 

그러므로 RL을 사용하여 산업의 문제를 풀고자 할때,

1.각 action에 따른 reward 설정을 적절하게 하여야 하며
2.여러가지 action을 선택하며 또한 좋은 action을 선택할수 있게 하여야 한다. 



## 2. 강화학습의 예


### 1.가젤

가젤은 태어난 직후에는 전혀 걷지 못하지만, 30분 뒤에는 1시간에 20마일을 달리는 있는 속도로 달릴만큼 빨라진다.


![gazelle-body-language-1](https://user-images.githubusercontent.com/11300712/38192903-406e101c-36aa-11e8-9243-d21ac90b006c.jpg)





### 2.아침 먹기 

![images](https://user-images.githubusercontent.com/11300712/38192899-3ec17042-36aa-11e8-9a62-ed691591af70.jpeg)

* 침대에서 일어난다

* 걸어서 복도를 통해 주방으로 간다

* 주방에서 밥솥을 연다

* 주걱을 잡아 밥을 접시에 담는다.

 


_ _ _


1번의 가젤 예제  :

Agent는  경험을 통하여 performance를 향상시키기 위해 계속 시도를 한다. 

2번의 아침먹기 예제:

Agent는 환경에 대해 정보가없으므로, Goal(목표)를 achieve(달성)하기 위해 환경과 상호작용하며 Decision-making 한다.


강화학습은 위의 예제처럼, 목표를 달성하기 위하여 환경과 상호작용을 하며, performance를 향상시키기 위한 action을 계속 선택한다. 


## 3. 강화학습의 요소

강화학습은 아래의 네 가지 요소로 구분이 가능하다. 

* Polcy

* Reward signal

* Value function

* model


- - -

**Policy : **

주어진 시간 ( given time ) 에 agent의 behavior

[action과 behavior의 사전적 의미 비교](http://geography.ruhosting.nl/geography/index.php?title=Behavior_vs._action ) 


_ _ _

**Reward Signal :** 

Reinforcement 문제의 Goal이라고 할 수 있다. 

* 매 Time step 마다 Reinforcement learning agent(강화학습 에이전트) 에게 Environment(환경)가 하나의 숫자를 보내는 것을 Reward라고 정의한다. 

* Reinforcement learning agent의 goal(목표)는 환경으로부터 받을 reward의 총합을 최대로 하는 것이다. 


_ _ _
**
Value function : 
**

Reward가 즉각적으로 받는것의 측정이라면, 

value function은 장기적인 reward의 측정이다. 

State의 value란 그 state에서 시작하여 미래까지 받을 수 있는 reward의 총 합을 측정하는 것이다. 

reward가 없다면 value는 존재하지 않을 것이라고 전제한다면, value를 측정하는것은 더 많은 reward를 얻기 위해 측정하는 것이므로 reward의 개념은 강화학습에서 매우 중요하다.

_ _ _

**
Model :
**

* 환경의 behavior을 모방 또는 환경의 behave를 추정

모델은 state와 action을 받고, next state와 reward를 return한다. 

Model은 planning에 쓰여지며, 실제로 경험하기 전에 가능한 미래 상황을 고려하여 action을 결정하는 것이다. 

RL 문제를 Model과 planning을 사용하여 해결하는 것을 model-based라고 하며,

반대로 Trial-and-error을 하며 배우는 것을 Model-Free라고 한다. 




_ _ _

###* 정리


강화학습의 거의 모든것 첫번째편에서는 

강화학습의 유례, 예제, 요소에 대해 알아보았다. 

강화학습은 dynamic system theory에서 근간하였으며, 

"목표지향적"으로 목표를 달성할때까지 받을 총 reward를 최대로 할 action을 선택한다. 

예로는 새끼 가젤과 아침먹기와 같이, 각 상황마다 행동을 선택하며 목표를 달성할때가지 계속 시도한다. 

강화학습의 요소는 아래와 같이 네가지이며,

* Polcy

* Reward signal

* Value function

* model

실제로 경험하며 배우는 것을 Model- free, 

Model에서 planning하는 것을 model-based라고 한다.



## Reference 
* Reinforcement Learning: An Introduction Richard S. Sutton and Andrew G. Barto Second Edition, in progress
MIT Press, Cambridge, MA, 2017



	



